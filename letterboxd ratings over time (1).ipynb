{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4878c555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "\n",
    "# Convert star symbols to float ratings\n",
    "def convert_stars_to_float(star_text):\n",
    "    if not star_text:\n",
    "        return None\n",
    "    half = '½' in star_text\n",
    "    stars = star_text.count('★')\n",
    "    return stars + 0.5 if half else stars\n",
    "\n",
    "def get_earliest_release_date(movie_name):\n",
    "    url = f\"https://letterboxd.com/film/{movie_name}\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch release page for {movie_name}\")\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    try:\n",
    "        release_table = soup.select_one('div.release-table.-bydate')\n",
    "        if not release_table:\n",
    "            print(\"No release table found.\")\n",
    "            return None\n",
    "\n",
    "        first_date_el = release_table.select_one('h5.date')\n",
    "        if not first_date_el:\n",
    "            print(\"No date element found.\")\n",
    "            return None\n",
    "\n",
    "        date_str = first_date_el.text.strip()\n",
    "        release_date = pd.to_datetime(date_str, errors='coerce')\n",
    "        print(f\"Earliest release date for {movie_name}: {release_date.date()}\")\n",
    "        return release_date\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing release date: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_reviews_from_page(url, release_date=None, latest_valid_date=None):\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch page: {url}\")\n",
    "        return []\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    review_elements = soup.select('article.production-viewing.-viewing')\n",
    "\n",
    "    reviews_on_page = []\n",
    "    now = pd.Timestamp.now().replace(tzinfo=None)\n",
    "    earliest_valid = pd.Timestamp(\"2011-10-01\")\n",
    "    latest_valid = latest_valid_date or (now + pd.Timedelta(days=365 * 3))\n",
    "    for review in review_elements:\n",
    "        rating_el = review.select_one('span.rating')\n",
    "        rating = convert_stars_to_float(rating_el.text.strip() if rating_el else None)\n",
    "\n",
    "        date_el = review.select_one('time')\n",
    "        raw_date_str = date_el['datetime'] if date_el else None\n",
    "\n",
    "        try:\n",
    "            date = pd.to_datetime(raw_date_str).replace(tzinfo=None)\n",
    "            if not (earliest_valid <= date <= latest_valid):\n",
    "                continue\n",
    "            if release_date and date < release_date:\n",
    "                continue\n",
    "            if date > now:\n",
    "                continue\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        if rating is not None:\n",
    "            reviews_on_page.append((date, rating))\n",
    "\n",
    "    return reviews_on_page\n",
    "\n",
    "def scrape_all_reviews(movie_name, base_urls):\n",
    "    all_reviews = []\n",
    "    release_date = get_earliest_release_date(movie_name)\n",
    "    latest_valid_date = pd.Timestamp.now().replace(tzinfo=None) + pd.Timedelta(days=365 * 3)\n",
    "    \n",
    "\n",
    "    for base_url in base_urls:\n",
    "        print(f'looking at {base_url}')\n",
    "        bad_pages = 0\n",
    "        page = 0\n",
    "        if not base_url.endswith(\"/\"):\n",
    "            base_url += \"/\"\n",
    "\n",
    "        while True:\n",
    "            print(f'scraping page {page}')\n",
    "            page_url = f\"{base_url}page/{page}/\"\n",
    "            reviews = get_reviews_from_page(\n",
    "                page_url,\n",
    "                release_date=release_date,\n",
    "                latest_valid_date=latest_valid_date\n",
    "            )\n",
    "            if reviews:\n",
    "                all_reviews.extend(reviews)\n",
    "            else:\n",
    "                bad_pages += 1\n",
    "            if bad_pages >= 5:\n",
    "                break\n",
    "            page += 4\n",
    "            time.sleep(random.uniform(1, 2))\n",
    "\n",
    "    return pd.DataFrame(all_reviews, columns=[\"date\", \"rating\"])\n",
    "\n",
    "def plot_review_data(df, movie_name):\n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce', utc=True)\n",
    "    df['date'] = df['date'].dt.tz_localize(None)\n",
    "    df = df.dropna(subset=['date'])\n",
    "    df_sorted = df.sort_values('date')\n",
    "\n",
    "    df_sorted['rolling_avg'] = df_sorted['rating'].rolling(window=50, min_periods=1).mean()\n",
    "\n",
    "    x_numeric = mdates.date2num(df_sorted['date'])\n",
    "    y = df_sorted['rating']\n",
    "\n",
    "    slope, intercept = np.polyfit(x_numeric, y, 1)\n",
    "    trendline = slope * x_numeric + intercept\n",
    "\n",
    "    start_date = df_sorted['date'].iloc[0]\n",
    "    end_date = df_sorted['date'].iloc[-1]\n",
    "    start_pred = slope * mdates.date2num(start_date) + intercept\n",
    "    end_pred = slope * mdates.date2num(end_date) + intercept\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.scatter(df_sorted['date'], df_sorted['rating'], alpha=0.5, label='Individual Ratings')\n",
    "    plt.plot(df_sorted['date'], df_sorted['rolling_avg'], color='red', linewidth=2, label='Rolling Average (50 reviews)')\n",
    "    plt.plot(df_sorted['date'], trendline, color='green', linestyle='--', linewidth=2, label='Trendline (Linear Fit)')\n",
    "\n",
    "    plt.scatter([start_date], [start_pred], color='blue', zorder=5, label=f'Start: {start_pred:.2f}')\n",
    "    plt.scatter([end_date], [end_pred], color='purple', zorder=5, label=f'End: {end_pred:.2f}')\n",
    "    plt.text(start_date, start_pred + 0.1, f\"{start_pred:.2f}\", color='blue', ha='left', va='bottom')\n",
    "    plt.text(end_date, end_pred + 0.1, f\"{end_pred:.2f}\", color='purple', ha='right', va='bottom')\n",
    "\n",
    "    plt.title(f\"{movie_name} — Ratings Over Time\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Rating\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    plt.ylim(0, 5.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab3096f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing white-chicks ---\n",
      "\n",
      "Earliest release date for white-chicks: 2004-06-23\n",
      "looking at https://letterboxd.com/film/white-chicks/reviews/by/added/\n",
      "scraping page 0\n",
      "scraping page 4\n",
      "scraping page 8\n",
      "scraping page 12\n",
      "scraping page 16\n",
      "scraping page 20\n",
      "scraping page 24\n",
      "scraping page 28\n",
      "scraping page 32\n",
      "scraping page 36\n",
      "scraping page 40\n",
      "scraping page 44\n",
      "scraping page 48\n",
      "scraping page 52\n",
      "scraping page 56\n",
      "scraping page 60\n",
      "scraping page 64\n",
      "scraping page 68\n",
      "scraping page 72\n",
      "scraping page 76\n",
      "scraping page 80\n",
      "scraping page 84\n",
      "scraping page 88\n",
      "scraping page 92\n",
      "scraping page 96\n",
      "scraping page 100\n",
      "scraping page 104\n",
      "scraping page 108\n",
      "scraping page 112\n",
      "scraping page 116\n",
      "scraping page 120\n",
      "scraping page 124\n",
      "scraping page 128\n",
      "scraping page 132\n",
      "scraping page 136\n",
      "scraping page 140\n",
      "scraping page 144\n",
      "scraping page 148\n",
      "scraping page 152\n",
      "scraping page 156\n",
      "scraping page 160\n",
      "scraping page 164\n",
      "scraping page 168\n",
      "scraping page 172\n",
      "scraping page 176\n",
      "scraping page 180\n",
      "scraping page 184\n",
      "scraping page 188\n",
      "scraping page 192\n",
      "scraping page 196\n",
      "scraping page 200\n",
      "scraping page 204\n",
      "scraping page 208\n",
      "scraping page 212\n",
      "scraping page 216\n",
      "scraping page 220\n",
      "scraping page 224\n",
      "scraping page 228\n",
      "scraping page 232\n",
      "scraping page 236\n",
      "scraping page 240\n",
      "scraping page 244\n",
      "scraping page 248\n",
      "scraping page 252\n",
      "scraping page 256\n",
      "scraping page 260\n",
      "scraping page 264\n",
      "scraping page 268\n",
      "scraping page 272\n",
      "scraping page 276\n",
      "looking at https://letterboxd.com/film/white-chicks/reviews/by/added-earliest/\n",
      "scraping page 0\n",
      "scraping page 4\n",
      "scraping page 8\n",
      "scraping page 12\n",
      "scraping page 16\n",
      "scraping page 20\n",
      "scraping page 24\n",
      "scraping page 28\n",
      "scraping page 32\n",
      "scraping page 36\n",
      "scraping page 40\n",
      "scraping page 44\n",
      "scraping page 48\n",
      "scraping page 52\n",
      "scraping page 56\n",
      "scraping page 60\n",
      "scraping page 64\n",
      "scraping page 68\n",
      "scraping page 72\n",
      "scraping page 76\n",
      "scraping page 80\n",
      "scraping page 84\n",
      "scraping page 88\n",
      "scraping page 92\n",
      "scraping page 96\n",
      "scraping page 100\n",
      "scraping page 104\n",
      "scraping page 108\n",
      "scraping page 112\n",
      "scraping page 116\n",
      "scraping page 120\n",
      "scraping page 124\n",
      "scraping page 128\n",
      "scraping page 132\n",
      "scraping page 136\n",
      "scraping page 140\n",
      "scraping page 144\n",
      "scraping page 148\n",
      "scraping page 152\n",
      "scraping page 156\n",
      "scraping page 160\n",
      "scraping page 164\n",
      "scraping page 168\n",
      "scraping page 172\n",
      "scraping page 176\n",
      "scraping page 180\n",
      "scraping page 184\n",
      "scraping page 188\n",
      "scraping page 192\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    movie_names = [\n",
    "        \"white-chicks\",\n",
    "        \"titanic\",\n",
    "        \"macgruber\",\n",
    "        \"tropic-thunder\",\n",
    "        \"blonde-2022\",\n",
    "        \"kinds-of-kindness\",\n",
    "        \"annihilation\",\n",
    "        \"the-lobster\",\n",
    "        \"midsommar\",\n",
    "        \"enter-the-void\"\n",
    "    ]\n",
    "\n",
    "    for movie_name in movie_names:\n",
    "        print(f\"\\n--- Processing {movie_name} ---\\n\")\n",
    "        base_urls = [\n",
    "            f\"https://letterboxd.com/film/{movie_name}/reviews/by/added/\",\n",
    "            f\"https://letterboxd.com/film/{movie_name}/reviews/by/added-earliest/\"\n",
    "        ]\n",
    "\n",
    "        df = scrape_all_reviews(movie_name, base_urls)\n",
    "\n",
    "        if df.empty:\n",
    "            print(f\"No reviews found for {movie_name}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Collected {len(df)} reviews for {movie_name}\")\n",
    "        plot_review_data(df, movie_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
